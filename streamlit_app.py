import streamlit as st
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

from src.preprocessing import (
    load_data,
    data_quality_report,
    missing_summary,
    detect_outliers_iqr,
    detect_outliers_zscore,
    prepare_features,
)


st.set_page_config(
    page_title="Analyse de la Qualit√© du Vin",
    page_icon="üç∑",
    layout="wide",
)

# Palette fixe pour que le vin rouge soit en rouge
WINE_PALETTE = {
    "red": "#d62728",    # rouge
    "white": "#ffdd8e",  # blanc l√©g√®rement dor√©
}


@st.cache_data
def load_combined_data() -> pd.DataFrame:
    """Charge et combine les donn√©es vin rouge / vin blanc."""
    root = Path(__file__).resolve().parent
    red_path = root / "data" / "winequality-red.csv"
    white_path = root / "data" / "winequality-white.csv"
    df = load_data(red_path, white_path)
    return df


@st.cache_data
def get_quality_reports(df: pd.DataFrame):
    """Pr√©pare les rapports de qualit√© de donn√©es et outliers."""
    report = data_quality_report(df)
    missing_df = missing_summary(df)
    iqr_outliers = detect_outliers_iqr(df)
    z_outliers = detect_outliers_zscore(df)
    return report, missing_df, iqr_outliers, z_outliers


@st.cache_data
def get_prepared_features(df: pd.DataFrame, threshold: int = 7):
    X, y, feature_cols = prepare_features(df, quality_threshold=threshold)
    return X, y, feature_cols


def build_regression_features(df: pd.DataFrame):
    """Pr√©pare les features pour la r√©gression de la note exacte."""
    df_reg = df.copy()
    # One-hot encode du type de vin (colonne binaire wine_type_white)
    df_reg = pd.get_dummies(df_reg, columns=["wine_type"], drop_first=True)
    feature_cols = [c for c in df_reg.columns if c != "quality"]
    X = df_reg[feature_cols]
    y = df_reg["quality"]
    return X, y, feature_cols


def main():
    df = load_combined_data()
    report, missing_df, iqr_outliers, z_outliers = get_quality_reports(df)

    st.title("Analyse de la Qualit√© du Vin")
    st.markdown(
        """
        Application Streamlit inspir√©e du notebook d'analyse exploratoire des vins **Vinho Verde**
        (rouge et blanc).  
        L'objectif est de **comprendre les donn√©es**, **pr√©parer les futures analyses**
        et **mettre en √©vidence les relations entre caract√©ristiques physicochimiques et qualit√©**.
        """
    )

    # Navigation principale
    section = st.sidebar.radio(
        "Navigation",
        (
            "1. Contexte & Donn√©es",
            "2. Pr√©paration des donn√©es",
            "3. Qualit√© des donn√©es",
            "4. Visualisations exploratoires",
            "5. Relations & hypoth√®ses",
            "6. R√©gression (note exacte)",
            "7. Interpr√©tation & limites",
        ),
    )

    st.sidebar.markdown("### Param√®tres")
    wine_filter = st.sidebar.multiselect(
        "Type de vin",
        options=sorted(df["wine_type"].unique()),
        default=list(sorted(df["wine_type"].unique())),
    )
    df_filtered = df[df["wine_type"].isin(wine_filter)].copy()

    if section == "1. Contexte & Donn√©es":
        show_context_and_data(df_filtered, df)
    elif section == "2. Pr√©paration des donn√©es":
        show_preparation(df_filtered)
    elif section == "3. Qualit√© des donn√©es":
        show_data_quality(df_filtered, report, missing_df, iqr_outliers, z_outliers)
    elif section == "4. Visualisations exploratoires":
        show_visualisations(df_filtered)
    elif section == "5. Relations & hypoth√®ses":
        show_relations_and_hypotheses(df_filtered)
    elif section == "6. R√©gression (note exacte)":
        show_regression(df_filtered)
    elif section == "7. Interpr√©tation & limites":
        show_conclusion(df_filtered)


def show_context_and_data(df: pd.DataFrame, df_full: pd.DataFrame):
    st.header("1. Compr√©hension des donn√©es")

    st.subheader("1.1 Contexte m√©tier & probl√©matique")
    st.markdown(
        """
        - **Domaine** : analyse sensorielle et ≈ìnologie sur les vins portugais *Vinho Verde*.  
        - **Probl√©matique** : pr√©dire la **qualit√© per√ßue** d'un vin √† partir de ses
          **mesures physicochimiques** (acidit√©, teneur en sucre, alcool, etc.).  
        - **Variable cible** : `quality`, note de 0 √† 10 issue de d√©gustations d'experts.
        """
    )

    st.subheader("1.2 Structure des jeux de donn√©es")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Nb. observations (total)", f"{len(df_full):,}".replace(",", " "))
    with col2:
        st.metric("Nb. variables", df_full.shape[1])
    with col3:
        st.metric("Types", "Toutes num√©riques + type de vin")

    st.markdown("#### Aper√ßu des donn√©es filtr√©es")
    st.dataframe(df.head())

    st.markdown("#### Description des variables")
    desc = {
        "fixed acidity": "Acidit√© fixe (acides non volatils)",
        "volatile acidity": "Acidit√© volatile (acides responsables du go√ªt de vinaigre)",
        "citric acid": "Acide citrique (fra√Æcheur, acidit√© vive)",
        "residual sugar": "Sucre r√©siduel apr√®s fermentation",
        "chlorides": "Chlorures (teneur en sel)",
        "free sulfur dioxide": "SO‚ÇÇ libre (agent conservateur)",
        "total sulfur dioxide": "SO‚ÇÇ total",
        "density": "Densit√© du vin",
        "pH": "Acidit√© globale (√©chelle 0-14)",
        "sulphates": "Sulfates (protection antimicrobienne)",
        "alcohol": "Teneur en alcool (%)",
        "quality": "Qualit√© sensorielle (0 = mauvais, 10 = excellent)",
        "wine_type": "Type de vin (rouge / blanc)",
    }
    desc_df = pd.DataFrame(
        [{"variable": k, "description": v} for k, v in desc.items()]
    )
    st.table(desc_df)


def show_preparation(df: pd.DataFrame):
    st.header("2. Pr√©parer les donn√©es pour les analyses")

    st.markdown(
        """
        Dans le notebook, la pr√©paration vise principalement √† :  
        - **Cr√©er une cible binaire** : distinguer les vins *bons* (qualit√© ‚â• seuil) des autres.  
        - **Encoder le type de vin** (`wine_type`) en variables num√©riques.  
        - **Standardiser** les variables num√©riques pour les mod√®les de machine learning.
        """
    )

    threshold = st.slider(
        "Seuil de qualit√© pour consid√©rer un vin comme ¬´ bon ¬ª (quality ‚â• seuil)",
        min_value=int(df["quality"].min()),
        max_value=int(df["quality"].max()),
        value=7,
        step=1,
    )

    X, y, feature_cols = get_prepared_features(df, threshold=threshold)

    st.subheader("2.1 Nouvelle variable cible")
    st.markdown(
        f"""
        - Une nouvelle variable `quality_label` est d√©finie :  
          - 1 ‚Üí vin **bon** (quality ‚â• {threshold})  
          - 0 ‚Üí vin **standard ou m√©diocre** (quality < {threshold})  
        - Cette transformation permet d'aborder le probl√®me en **classification binaire**.
        """
    )

    st.write("R√©partition de `quality` et de `quality_label` :")
    col1, col2 = st.columns(2)
    with col1:
        st.bar_chart(df["quality"].value_counts().sort_index())
    with col2:
        label_counts = y.value_counts().rename(index={0: "0 (non-bon)", 1: "1 (bon)"})
        st.bar_chart(label_counts)

    st.subheader("2.2 Matrice de caract√©ristiques apr√®s pr√©paration")
    st.markdown(
        """
        - Les colonnes incluent les mesures physicochimiques et un encodage du type de vin.  
        - Cette matrice est pr√™te √† √™tre **scal√©e** puis utilis√©e dans des mod√®les
          (r√©gression, arbres, SVM, etc.).
        """
    )
    st.write("Aper√ßu des features (X) :")
    st.dataframe(X.head())

    st.markdown(
        """
        **Justification des choix de pr√©paration** :  
        - La cible binaire facilite l'interpr√©tation m√©tier (*bons vs autres vins*).  
        - L'encodage `wine_type` permet de capturer les diff√©rences structurelles rouge/blanc.  
        - Le scaling (dans le pipeline complet) est adapt√© aux mod√®les sensibles √† l'√©chelle
          des variables (SVM, r√©gression logistique, etc.).
        """
    )


def show_data_quality(
    df: pd.DataFrame,
    report: dict,
    missing_df: pd.DataFrame,
    iqr_outliers: pd.DataFrame,
    z_outliers: pd.DataFrame,
):
    st.header("3. V√©rification de la qualit√© des donn√©es")

    st.subheader("3.1 Valeurs manquantes")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("Nb. lignes", report["rows"])
    with c2:
        st.metric("Nb. colonnes", report["cols"])
    with c3:
        st.metric("Valeurs manquantes (total)", report["missing_total"])

    st.markdown(
        """
        - Le dataset d'origine ne contient **aucune valeur manquante** (comme v√©rifi√© dans le notebook).  
        - Les √©ventuels traitements de valeurs manquantes ne sont donc **pas n√©cessaires** ici.
        """
    )

    st.subheader("3.2 Types de donn√©es")
    st.write(pd.Series(report["dtypes"], name="dtype").to_frame())

    st.subheader("3.3 D√©tection des outliers")
    st.markdown(
        """
        Nous utilisons deux approches compl√©mentaires :  
        - **R√®gle de l'IQR (Interquartile Range)** : points situ√©s en dehors \[Q1 ‚àí 1.5√óIQR ; Q3 + 1.5√óIQR\].  
        - **Z-score** : points dont la distance √† la moyenne d√©passe un certain seuil (ici 3 √©carts-types).
        """
    )

    tabs = st.tabs(["R√©sum√© IQR", "R√©sum√© Z-score", "Boxplots"])
    with tabs[0]:
        st.write("Outliers par variable (IQR) :")
        st.dataframe(iqr_outliers)
    with tabs[1]:
        st.write("Outliers par variable (Z-score) :")
        st.dataframe(z_outliers)
    with tabs[2]:
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        selected_cols = st.multiselect(
            "Variables √† afficher en boxplot",
            options=numeric_cols,
            default=["alcohol", "residual sugar", "chlorides"],
        )
        if selected_cols:
            fig, ax = plt.subplots(figsize=(10, 4))
            sns.boxplot(data=df[selected_cols], ax=ax)
            ax.set_title("Boxplots des variables s√©lectionn√©es")
            st.pyplot(fig)

    st.markdown(
        """
        **Gestion des outliers (strat√©gie adopt√©e)** :  
        - Les outliers refl√®tent souvent des **cas r√©els extr√™mes** (vins tr√®s sucr√©s, tr√®s acides, etc.).  
        - Plut√¥t que de les supprimer syst√©matiquement, la strat√©gie recommand√©e est de :  
          - Les **analyser** (impact sur les mod√®les, stabilit√© des coefficients).  
          - √âventuellement les **caper** (clipper) si l'on observe une sensibilit√© excessive de certains mod√®les.
        """
    )


def show_visualisations(df: pd.DataFrame):
    st.header("4. Visualisations exploratoires")

    st.subheader("4.1 Distribution de la qualit√©")
    col1, col2 = st.columns(2)
    with col1:
        fig, ax = plt.subplots()
        sns.countplot(x="quality", data=df, hue="wine_type", ax=ax, palette=WINE_PALETTE)
        ax.set_title("Distribution de la qualit√© par type de vin")
        st.pyplot(fig)
    with col2:
        st.markdown(
            """
            - La majorit√© des vins se situe entre **5 et 7**.  
            - Tr√®s peu de vins sont not√©s comme **exceptionnels** (8‚Äì9) ou **tr√®s mauvais** (‚â§4).  
            - Cette **asym√©trie** justifie de traiter la qualit√© comme une variable **ordinale/d√©s√©quilibr√©e**.
            """
        )

    st.subheader("4.2 Distributions univari√©es")
    feature = st.selectbox(
        "Choisir une variable num√©rique √† explorer",
        options=df.select_dtypes(include=[np.number]).columns.tolist(),
        index=0,
    )
    fig, ax = plt.subplots()
    sns.histplot(
        df,
        x=feature,
        hue="wine_type",
        kde=True,
        ax=ax,
        element="step",
        palette=WINE_PALETTE,
    )
    ax.set_title(f"Distribution de {feature} par type de vin")
    st.pyplot(fig)

    st.subheader("4.3 Corr√©lation globale")
    numeric_df = df.select_dtypes(include=[np.number])
    corr = numeric_df.corr()
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.heatmap(corr, cmap="coolwarm", center=0, annot=False, ax=ax)
    ax.set_title("Matrice de corr√©lation (variables num√©riques)")
    st.pyplot(fig)

    st.markdown(
        """
        **Exemples de tendances visibles (issues du notebook)** :  
        - L'**alcool** est g√©n√©ralement **positivement corr√©l√©** √† la qualit√©.  
        - Une **acidit√© volatile √©lev√©e** (go√ªt vinaigr√©) tend √† √™tre **n√©gativement corr√©l√©e** √† la qualit√©.  
        - Certaines variables sont fortement corr√©l√©es entre elles (ex. SO‚ÇÇ libre / total), ce qui
          invite √† une **s√©lection de variables** ou √† des m√©thodes robustes √† la colin√©arit√©.
        """
    )


def show_relations_and_hypotheses(df: pd.DataFrame):
    st.header("5. Relations entre variables & hypoth√®ses")

    st.subheader("5.1 Relations qualit√© vs caract√©ristiques cl√©s")
    x_var = st.selectbox(
        "Variable explicative",
        options=[
            "alcohol",
            "volatile acidity",
            "citric acid",
            "residual sugar",
            "sulphates",
            "pH",
            "density",
        ],
        index=0,
    )

    fig, ax = plt.subplots()
    sns.boxplot(
        x="quality",
        y=x_var,
        data=df,
        hue="wine_type",
        ax=ax,
        palette=WINE_PALETTE,
    )
    ax.set_title(f"{x_var} en fonction de la qualit√©")
    st.pyplot(fig)

    st.markdown(
        """
        **Exemple d'interpr√©tation** (√† adapter selon la variable choisie) :  
        - `alcohol` : les vins les mieux not√©s ont en moyenne une **teneur en alcool plus √©lev√©e**.  
        - `volatile acidity` : les vins de mauvaise qualit√© pr√©sentent souvent une **acidit√© volatile plus forte** pour les **vins Rouges**.
        - `residual sugar` : le sucre r√©siduel peut diff√©rencier certains styles de vins blancs.
        """
    )

    st.subheader("5.2 Hypoth√®ses de travail")
    st.markdown(
        """
        √Ä partir des observations exploratoires, on peut formuler plusieurs hypoth√®ses :  
        - **H1** : plus l'alcool est √©lev√© (dans des limites raisonnables), plus la qualit√© per√ßue augmente.  
        - **H2** : une acidit√© volatile trop forte d√©grade la perception de qualit√© des vins Rouges.  
        - **H3** : le type de vin (rouge vs blanc) module l'effet de certaines variables sur la qualit√©.  

        **Choix de mod√®les possibles** (comme discut√© dans le notebook) :  
        - **R√©gression** (lin√©aire, r√©gularis√©e) pour pr√©dire la note exacte.  
        - **Classification** (logistique, arbres, Random Forest, SVM) pour pr√©dire *bon* vs *non bon*.  
        - Les mod√®les √† marge large comme les **SVM** sont bien adapt√©s √† ce type de donn√©e
          num√©riquement homog√®ne et ont montr√© de bonnes performances dans la litt√©rature.
        """
    )


def show_regression(df: pd.DataFrame):
    st.header("6. R√©gression lin√©aire pour pr√©dire la note exacte")

    st.markdown(
        """
        Nous entra√Ænons ici un mod√®le de **r√©gression lin√©aire (avec ou sans r√©gularisation)**  
        pour pr√©dire directement la note de qualit√© `quality` (0‚Äì10) √† partir des
        caract√©ristiques physicochimiques et du type de vin.
        """
    )

    model_type = st.selectbox(
        "Choisir le type de mod√®le",
        options=["R√©gression lin√©aire", "Ridge (L2)", "Lasso (L1)"],
        index=1,
    )

    alpha = None
    if model_type in ("Ridge (L2)", "Lasso (L1)"):
        alpha = st.slider(
            "Coefficient de r√©gularisation (alpha)",
            min_value=0.01,
            max_value=10.0,
            value=1.0,
            step=0.01,
        )

    # Pr√©paration des donn√©es pour la r√©gression
    X, y, feature_cols = build_regression_features(df)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Choix du mod√®le
    if model_type == "R√©gression lin√©aire":
        model = LinearRegression()
    elif model_type == "Ridge (L2)":
        model = Ridge(alpha=alpha, random_state=42)
    else:  # Lasso
        model = Lasso(alpha=alpha, random_state=42)

    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    st.subheader("6.1 Performances du mod√®le sur le jeu de test")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("MAE", f"{mae:.3f}")
    with c2:
        st.metric("RMSE", f"{rmse:.3f}")
    with c3:
        st.metric("R¬≤", f"{r2:.3f}")

    st.markdown(
        """
        - **MAE** : erreur absolue moyenne en points de qualit√©.  
        - **RMSE** : p√©nalise davantage les grandes erreurs.  
        - **R¬≤** : proportion de la variance de `quality` expliqu√©e par le mod√®le.
        """
    )

    st.subheader("6.2 Pr√©diction vs valeur r√©elle")
    fig, ax = plt.subplots()
    ax.scatter(y_test, y_pred, alpha=0.5)
    min_q = min(y_test.min(), y_pred.min())
    max_q = max(y_test.max(), y_pred.max())
    ax.plot([min_q, max_q], [min_q, max_q], "k--", label="y = x")
    ax.set_xlabel("Qualit√© r√©elle")
    ax.set_ylabel("Qualit√© pr√©dite")
    ax.set_title("Qualit√© r√©elle vs pr√©dite (jeu de test)")
    ax.legend()
    st.pyplot(fig)

    st.subheader("6.3 Poids des variables (coefficients)")
    if hasattr(model, "coef_"):
        coef_series = pd.Series(model.coef_, index=feature_cols)
        coef_sorted = coef_series.reindex(coef_series.abs().sort_values(ascending=False).index)
        st.write("Top variables (en valeur absolue des coefficients) :")
        st.dataframe(coef_sorted.to_frame("coefficient"))

        fig, ax = plt.subplots(figsize=(8, 5))
        coef_sorted.head(15).plot(kind="barh", ax=ax)
        ax.set_title("Principales variables explicatives selon le mod√®le")
        ax.invert_yaxis()
        st.pyplot(fig)

    st.markdown(
        """
        **Interpr√©tation** :  
        - Les coefficients indiquent comment la note de qualit√© varie en moyenne lorsqu'une
          variable augmente d'une unit√© (toutes choses √©gales par ailleurs).  
        - La r√©gularisation (**Ridge / Lasso**) permet de **stabiliser** le mod√®le et de
          limiter le sur-apprentissage, en particulier en pr√©sence de variables corr√©l√©es.
        """
    )


def show_conclusion(df: pd.DataFrame):
    st.header("6. Interpr√©tation globale & limites")

    st.subheader("6.1 Synth√®se des principaux r√©sultats exploratoires")
    st.markdown(
        """
        - Les jeux de donn√©es (rouge et blanc) sont **propres**, sans valeurs manquantes,
          et bien document√©s.  
        - La qualit√© des vins est **mod√©r√©ment corr√©l√©e** avec certaines variables cl√©s
          (alcool, acidit√© volatile, sulfates, etc.).  
        - La distribution de `quality` est **d√©s√©quilibr√©e**, avec peu d'extr√™mes.
        """
    )

    st.subheader("6.2 Interpr√©tation statistique & significativit√© (niveau exploratoire)")
    st.markdown(
        """
        - Les corr√©lations observ√©es servent de **pistes** mais ne suffisent pas √† √©tablir
          une **causalit√©**.  
        - Des tests plus formels (tests de corr√©lation, mod√®les param√©triques) peuvent √™tre
          int√©gr√©s dans un second temps pour quantifier la **significativit√©**.  
        - La granularit√© de la note (0‚Äì10) et la subjectivit√© du jugement humain imposent
          une certaine **incertitude** sur la cible.
        """
    )

    st.subheader("6.3 Limitations")
    st.markdown(
        """
        - Absence d'informations sur le **prix**, la **marque**, le **mill√©sime** ou la **r√©gion pr√©cise**.  
        - Les donn√©es proviennent d'une seule appellation (*Vinho Verde*), ce qui limite
          la **g√©n√©ralisation** √† d'autres types de vins.  
        - La qualit√© est une mesure **subjective**, m√™me si elle repose sur plusieurs experts.
        """
    )

    st.subheader("6.4 Perspectives")
    st.markdown(
        """
        - Int√©grer des **mod√®les pr√©dictifs** (SVM, Random Forest, Gradient Boosting) dans
          cette application pour comparer leurs performances.  
        - Explorer des approches de **s√©lection de variables** pour r√©duire la dimension
          et am√©liorer l'interpr√©tabilit√©.  
        - √âtendre l'analyse √† d'autres datasets de vins afin de tester la **robustesse**
          des conclusions actuelles.
        """
    )

    st.info(
        "Cette application Streamlit r√©sume le notebook en une pr√©sentation structur√©e : "
        "compr√©hension des donn√©es, qualit√©, pr√©paration, exploration visuelle, "
        "formulation d'hypoth√®ses et conclusions."
    )


if __name__ == "__main__":
    main()
